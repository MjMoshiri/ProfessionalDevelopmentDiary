# AI Engineer Professional Certificate
**[AI Engineer Professional Certificate on Coursera](https://www.coursera.org/professional-certificates/ai-engineer)**: Started the journey.

## Courses Completed
- **[Machine Learning with Python](https://www.coursera.org/learn/machine-learning-with-python)**: First course completed.

## Important Notes to Remember

### Unsupervised Learning
- **Previously Unknown Information**: A key goal of unsupervised learning is to discover previously unknown information in the data.
- **Reduction**: Unsupervised learning can be used for dimensionality reduction, which is useful for visualization and feature selection.
- **Density Estimation**: Unsupervised learning can be used for density estimation, which is useful for anomaly detection.

### Statistical Models
- **Ordinary Least Squares**: A method for estimating the unknown parameters in a linear regression model.

### Evaluation Metrics
- **Jaccard Index**: Used for comparing the similarity and diversity of sample sets.
- **F1 Score**: The harmonic mean of precision and recall.
- **Log Loss**: A performance metric for evaluating the accuracy of classifiers.

### Decision Trees
- **Pure Node**: A node that contains only one class.
- **Entropy**: A measure of impurity in a set of data.
- **Information Gain**: The reduction in entropy or impurity after a dataset is split. Key to building decision trees.

### Tools
- **SnapML**: A library similar to Scikit-learn but optimized to utilize both GPU and CPU threads.

### Trees
- **Regression Tree**: A decision tree used for regression tasks rather than classification.
- **Decision Boundary**: The boundary that separates different classes in a classification problem.

### Multi-Class Classification
- **One vs All (OvA)**: A strategy for multi-class classification where a binary classifier is trained for each class.
- **One vs One (OvO)**: A strategy for multi-class classification where a binary classifier is trained for each pair of classes.
- **Softmax Function**: A function that converts raw scores into probabilities for multi-class classification.
- **Kernel Trick**: A technique used to transform data into a higher-dimensional space to make it linearly separable.

### Clustering Techniques
- **Partitioned Clustering**: A type of clustering where data is divided into non-overlapping clusters. (K-means)
- **Hierarchical Clustering**: A type of clustering where clusters are created in a tree-like structure. (Agglomerative, Divisive)
- **Density-Based Clustering**: A type of clustering that identifies clusters based on the density of data points. (DBSCAN)
- **Elbow Shape in K-means**: A technique used to determine the number of clusters in K-means clustering.

**Tags**: Machine Learning, AI