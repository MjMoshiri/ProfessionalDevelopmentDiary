# 2023-07-20

Exciting progress today as I delved deeper into machine learning methods and achieved a new high score in a Kaggle competition! Here's a summary:

- **[Hyperparameter Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)**: I learned about parameter tuning, cross-validation (CV), and grid search techniques. Also discovered two Python libraries, Optuna and Hyperopt, that help in the process of hyperparameter optimization.

- **[OneHotEncoder vs OrdinalEncoder](https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/)**: Explored the differences between OneHotEncoder and OrdinalEncoder, two techniques used for handling categorical data in machine learning models.

- **[Catboost](https://catboost.ai/)**: Discovered Catboost, a high-performance open source library for gradient boosting on decision trees.

- **Kaggle Competition Update**: The learning has been fruitful. I improved my score from 0.783 to 0.796, and I climbed up the rankings, moving from 1800 to 1000!

**Tags**: Hyperparameter Optimization, Optuna, Hyperopt, OneHotEncoder, OrdinalEncoder, Catboost, Kaggle
